{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "TEST_QUERIES = [\n",
    "    \"What are the key capabilities of Gemini models?\",\n",
    "    \"How does Gemini compare to other multimodal models?\", \n",
    "    \"What are the different versions of Gemini?\"\n",
    "]\n",
    "\n",
    "MAX_TOKENS_VALUES = [50, 100, 200, 400, 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Admin\\Desktop\\para-expe\\data\\rag_embeddings.pkl', 'rb') as f:\n",
    "    rag_data = pickle.load(f)\n",
    "\n",
    "chunks = rag_data['chunks']\n",
    "embeddings = rag_data['embeddings']\n",
    "\n",
    "def get_embedding(text):\n",
    "    return client.embeddings.create(input=[text.replace(\"\\n\", \" \")], model=\"text-embedding-3-small\").data[0].embedding\n",
    "\n",
    "def retrieve_chunks(query, k=5):\n",
    "    query_embedding = get_embedding(query)\n",
    "    similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:k]\n",
    "    return [chunks[idx]['text'] for idx in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(query, max_tokens):\n",
    "    context = \"\\n\\n\".join(retrieve_chunks(query))\n",
    "    \n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"tokens_used\": response.usage.completion_tokens,\n",
    "        \"answer\": answer,\n",
    "        \"word_count\": len(answer.split())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 50 tokens for: What are the key capabilities of Gemini ...\n",
      "Testing 100 tokens for: What are the key capabilities of Gemini ...\n",
      "Testing 200 tokens for: What are the key capabilities of Gemini ...\n",
      "Testing 400 tokens for: What are the key capabilities of Gemini ...\n",
      "Testing 800 tokens for: What are the key capabilities of Gemini ...\n",
      "Testing 50 tokens for: How does Gemini compare to other multimo...\n",
      "Testing 100 tokens for: How does Gemini compare to other multimo...\n",
      "Testing 200 tokens for: How does Gemini compare to other multimo...\n",
      "Testing 400 tokens for: How does Gemini compare to other multimo...\n",
      "Testing 800 tokens for: How does Gemini compare to other multimo...\n",
      "Testing 50 tokens for: What are the different versions of Gemin...\n",
      "Testing 100 tokens for: What are the different versions of Gemin...\n",
      "Testing 200 tokens for: What are the different versions of Gemin...\n",
      "Testing 400 tokens for: What are the different versions of Gemin...\n",
      "Testing 800 tokens for: What are the different versions of Gemin...\n",
      "Completed 15 experiments\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for query in TEST_QUERIES:\n",
    "    for max_tokens in MAX_TOKENS_VALUES:\n",
    "        print(f\"Testing {max_tokens} tokens for: {query[:40]}...\")\n",
    "        result = run_experiment(query, max_tokens)\n",
    "        results.append(result)\n",
    "        time.sleep(1)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(f\"Completed {len(results)} experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>max_tokens</th>\n",
       "      <th>tokens_used</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the key capabilities of Gemini models?</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the key capabilities of Gemini models?</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the key capabilities of Gemini models?</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the key capabilities of Gemini models?</td>\n",
       "      <td>400</td>\n",
       "      <td>378</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the key capabilities of Gemini models?</td>\n",
       "      <td>800</td>\n",
       "      <td>419</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does Gemini compare to other multimodal mo...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does Gemini compare to other multimodal mo...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does Gemini compare to other multimodal mo...</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does Gemini compare to other multimodal mo...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does Gemini compare to other multimodal mo...</td>\n",
       "      <td>800</td>\n",
       "      <td>437</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What are the different versions of Gemini?</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What are the different versions of Gemini?</td>\n",
       "      <td>100</td>\n",
       "      <td>49</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What are the different versions of Gemini?</td>\n",
       "      <td>200</td>\n",
       "      <td>43</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What are the different versions of Gemini?</td>\n",
       "      <td>400</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What are the different versions of Gemini?</td>\n",
       "      <td>800</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  max_tokens  \\\n",
       "0     What are the key capabilities of Gemini models?          50   \n",
       "1     What are the key capabilities of Gemini models?         100   \n",
       "2     What are the key capabilities of Gemini models?         200   \n",
       "3     What are the key capabilities of Gemini models?         400   \n",
       "4     What are the key capabilities of Gemini models?         800   \n",
       "5   How does Gemini compare to other multimodal mo...          50   \n",
       "6   How does Gemini compare to other multimodal mo...         100   \n",
       "7   How does Gemini compare to other multimodal mo...         200   \n",
       "8   How does Gemini compare to other multimodal mo...         400   \n",
       "9   How does Gemini compare to other multimodal mo...         800   \n",
       "10         What are the different versions of Gemini?          50   \n",
       "11         What are the different versions of Gemini?         100   \n",
       "12         What are the different versions of Gemini?         200   \n",
       "13         What are the different versions of Gemini?         400   \n",
       "14         What are the different versions of Gemini?         800   \n",
       "\n",
       "    tokens_used  word_count  \n",
       "0            50          38  \n",
       "1           100          72  \n",
       "2           200         137  \n",
       "3           378         275  \n",
       "4           419         303  \n",
       "5            50          35  \n",
       "6           100          69  \n",
       "7           200         141  \n",
       "8           400         306  \n",
       "9           437         340  \n",
       "10           47          35  \n",
       "11           49          37  \n",
       "12           43          33  \n",
       "13           20          16  \n",
       "14           93          70  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['query', 'max_tokens', 'tokens_used', 'word_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b9be8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The key capabilities of Gemini models include:\\n\\n1. **Multimodal Processing**: Gemini models can handle and integrate multiple data types, including text, code, images, audio, and video, allowing for versatile applications across various domains.\\n\\n2. **Advanced Reasoning**: The models exhibit strong reasoning capabilities, enabling them to tackle complex multi-step problems and perform tasks that require deliberate reasoning and understanding of context.\\n\\n3. **High Performance on Benchmarks**: Gemini Ultra, the most capable model in'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['answer'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb0380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
